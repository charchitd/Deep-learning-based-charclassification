{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ee38eea81c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# this is the main model structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 32, 32\n",
    "\n",
    "train_data_dir = 'final_testcopy' # Train data Directory\n",
    "validation_data_dir = 'final_testcopy' # Test1 data Directory\n",
    "\n",
    "\n",
    "nb_train_samples = 36000 # Training samples\n",
    "nb_validation_samples = 7200# Test Samples \n",
    "epochs = 50 # Number of epochs\n",
    "batch_size = 16 \n",
    "\n",
    "# This checks when to put channels first\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# This is the main model structure\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape)) # First convolution Layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))     #Second Convolution Layer\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))    #Third Convolution Layer\n",
    "\n",
    "model.add(Flatten())                     #Flatten the layers\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(36))                     #As classes are 36, model.add(Dense(36))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# This is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=False) # Flip = False as it we need to retain Characters\n",
    "\n",
    "# This is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Fit the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples / batch_size, \n",
    "    epochs=epochs)\n",
    "#  validation_data=validation_generator,\n",
    "#  validation_steps=0 // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5') # Save the trained model to file\n",
    "# To avoid error below, from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(36))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    if show:\n",
    "        plt.imshow(img)                           \n",
    "        plt.axis('off')\n",
    "        \n",
    "#  To plot images\n",
    "        \n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    \n",
    "\n",
    "    return img_tensor # Return tensor(Array)\n",
    "\n",
    "def load_trained_model(weights_path, image_path):\n",
    "    model = create_model()\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    \n",
    "    image = load_image(image_path, show=True) # load image, rescale to 0 to 1\n",
    "    \n",
    "    class_ = model.predict(image) # predict the output, returns 36 length array\n",
    "    \n",
    "    print(\"Detected: \", class_[0])\n",
    "    \n",
    "    output_indice = -1 # set it initially to -1\n",
    "    \n",
    "    for i in range(36):\n",
    "        if(i == 0):\n",
    "            max = class_[0][i]\n",
    "            output_indice = 0\n",
    "        else:\n",
    "            if(class_[0][i] > max):\n",
    "                max = class_[0][i]\n",
    "                output_indice = i\n",
    "                \n",
    "    characters = []\n",
    "    for i in range(65, 65+26):\n",
    "        characters.append(chr(i))\n",
    "    \n",
    "    if(output_indice > 9):\n",
    "        final_result = characters[(output_indice - 9) - 1]\n",
    "        print(\"Predicted: \", final_result)\n",
    "        print(\"value: \", max)\n",
    "    else:\n",
    "        print(\"Predicted: \", output_indice)\n",
    "        print(\"value: \", max)\n",
    "    # this is the augmentation configuration we will use for testing:\n",
    "    # only rescaling\n",
    "    #   test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Detected: ', array([0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       1.000000e+00, 0.000000e+00, 3.861468e-15, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
      "       0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00],\n",
      "      dtype=float32))\n",
      "('Predicted: ', 'O')\n",
      "('value: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "load_trained_model(\"first_tryy.h5\", \"o.jpg\")  # Call load_trained_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
